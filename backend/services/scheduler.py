import asyncio
import logging
from concurrent.futures import ProcessPoolExecutor
from sqlalchemy import desc
from typing import Dict, List
from datetime import datetime
import traceback

from database.crud import get_crud_for_table
from database import get_db_session
from .parsers import parse
from .forecasting import forecast
from logger import Logger

logger = Logger().get_logger()


class Scheduler:
    def __init__(self, tasks_config: List[Dict], process_pool: ProcessPoolExecutor):
        """
        –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Å –∑–∞–ø—É—Å–∫–æ–º –∑–∞–¥–∞—á –≤ –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö
        
        :param tasks_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–¥–∞—á
        :param process_pool: –ü—É–ª –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á
        """
        self.tasks_config = tasks_config
        self.process_pool = process_pool
        self._running_tasks = []
        self._shutdown_event = asyncio.Event()

    async def start(self):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—É—Å–∫ –≤—Å–µ—Ö –∑–∞–¥–∞—á"""
        logger.info(f"üöÄ Starting scheduler with {len(self.tasks_config)} tasks")

        for task_config in self.tasks_config:
            task = asyncio.create_task(
                self._process_task_wrapper(task_config)
            )
            self._running_tasks.append(task)

        logger.info("‚úÖ All tasks running in background")

    async def _process_task_wrapper(self, task_config: Dict):
        """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∑–∞–¥–∞—á–∏ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ"""
        loop = asyncio.get_running_loop()

        while not self._shutdown_event.is_set():
            try:
                start_time = loop.time()
                await loop.run_in_executor(
                    self.process_pool,
                    self._process_task,
                    task_config
                )    
                execution_time = loop.time() - start_time
                sleep_time = max(0, task_config['schedule']['pooling_interval'] - execution_time)
                await asyncio.sleep(sleep_time)

            except Exception as e:
                logger.info(f"‚ö†Ô∏è Task '{task_config['name']}' failed: {str(e)}")
                logger.info(traceback.format_exc())
                logger.info(f"üîÑ Retrying in {task_config['schedule']['retry_cooldown']}s...")
                await asyncio.sleep(task_config['schedule']['retry_cooldown'])

    @staticmethod
    def _process_task(task_config: Dict) -> bool:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ
        
        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
            task_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–¥–∞—á–∏ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –ø–∞—Ä—Å–µ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏
            
        –ò—Å–∫–ª—é—á–µ–Ω–∏—è:
            ValueError: –ü—Ä–∏ –æ—à–∏–±–∫–∞—Ö –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        logger.info(f"\n{'='*50}")
        logger.info(f"üîß Starting task: {task_config['name']} ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})")
        logger.info(f"üìå Table: {task_config['database']['tablename']}")
        logger.info(f"üîÆ Model: {task_config['model']['type']}")
        logger.info(f"{'='*50}")

        try:
            # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Å–µ—Å—Å–∏—é –ë–î
            db_session = next(get_db_session())

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –Ω–µ–Ω—É–ª–µ–≤–æ–≥–æ endog –∏–∑ –ë–î
            tablename = task_config['database']['tablename']
            crud = get_crud_for_table(tablename)
            last_observation = (
                db_session.query(crud.model)
                .filter(crud.model.endog.isnot(None))
                .order_by(desc(crud.model.date))
                .first()
            )
            last_obs_date = last_observation.date if last_observation else None
            logger.info(f"\nüìÖ Last observation date in DB: {last_obs_date or 'No data'}")

            # –ü–∞—Ä—Å–∏–º –Ω–æ–≤—ã–µ –Ω–∞–±–ª—é–¥–∞–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ
            logger.info("\nüîÑ Fetching new data from source...")
            parsed_data = parse(
                parser_type=task_config['parser']['type'],
                params=task_config['parser']['params']
            )
            logger.info(f"‚úÖ Received {len(parsed_data['dates'])} data points")
            logger.info(f"üìÜ Date range: {parsed_data['dates'][0]} to {parsed_data['dates'][-1]}")

            # –§–∏–ª—å—Ç—Ä—É–µ–º –Ω–∞–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –≤—ã—á–∏—Å–ª—è–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
            updated_forecasts = 0
            new_observations = []
            for i, date in enumerate(parsed_data["dates"]):
                if not last_obs_date or date > last_obs_date:
                    existing_record = db_session.query(crud.model)\
                                    .filter(crud.model.date == date)\
                                    .first()       
                    if existing_record and existing_record.predict is not None:
                        existing_record.endog = parsed_data["endog"][i]
                        if parsed_data["endog"][i] is not None:
                            existing_record.absolute_error = abs(parsed_data["endog"][i] - existing_record.predict)
                        updated_forecasts += 1
                        logger.info(f"üîÑ Updated forecast for {date} with actual data")
                    else:
                        new_observations.append({
                            "date": date, 
                            "endog": parsed_data["endog"][i],
                            "predict": None,
                            "ci_low": None,
                            "ci_up": None,
                            "conf_level": None, 
                            "absolute_error": None,  
                            "last_summary": None,
                        })  
            if updated_forecasts > 0:
                db_session.commit()
                logger.info(f"üìä Updated {updated_forecasts} existing forecasts with actual data")
            if new_observations:
                crud.bulk_create(db_session, new_observations)
                logger.info(f"üíæ Saved {len(new_observations)} new observations")
            else:
                logger.info("\nüÜó No new observations to save")
            if not updated_forecasts and not new_observations:
                return True

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
            observation_window_size = task_config['model']['observation_window_size']
            logger.info(f"\nüîç Loading last {observation_window_size} observations for forecasting...")
            observations_for_forecast = db_session.query(crud.model)\
                            .filter(crud.model.endog.isnot(None))\
                            .order_by(desc(crud.model.date))\
                            .limit(observation_window_size)\
                            .all()

            if not observations_for_forecast:
                raise ValueError("No training data available")
            
            logger.info(f"üìä Observations loaded: {len(observations_for_forecast)} points")
            logger.info(f"üìÜ From {observations_for_forecast[-1].date} to {observations_for_forecast[0].date}")  

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
            forecast_input = {
                'endog': [obs.endog for obs in reversed(observations_for_forecast)],
                'dates': [obs.date for obs in reversed(observations_for_forecast)]
            }

            # –°—Ç—Ä–æ–∏–º –ø—Ä–æ–≥–Ω–æ–∑
            logger.info('forecast_input: ', forecast_input)
            logger.info("\nüîÆ Running forecast...")
            forecast_result = forecast(
                data=forecast_input,
                model_type=task_config['model']['type'],
                settings=task_config['model']['params']
            )
            logger.info(f"‚úÖ Forecast completed for {len(forecast_result['prediction'])} future points")

            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –≤ –ë–î
            historical_len = len(forecast_input['endog'])
            forecast_dates = forecast_result['full_dates'][historical_len:]
            logger.info(f"\nüìù Updating {len(forecast_dates)} forecast points in DB...")
            
            updated = 0
            created = 0
            for pred_idx, date in enumerate(forecast_dates):
                existing = db_session.query(crud.model)\
                            .filter(crud.model.date == date)\
                            .first()
                
                update_data = {
                    'predict': forecast_result['prediction'][pred_idx],
                    'ci_low': forecast_result['confidence_intervals']['intervals'][pred_idx][0],
                    'ci_up': forecast_result['confidence_intervals']['intervals'][pred_idx][1],
                    'conf_level': forecast_result['confidence_intervals']['confidence_level'],
                    'last_summary': forecast_result['summary'] if pred_idx == len(forecast_dates)-1 else None
                }
                
                if existing:
                    updated += 1
                    for key, value in update_data.items():
                        setattr(existing, key, value)
                else:
                    created += 1
                    new_forecast = crud.model(
                        date=date,
                        endog=None,
                        **update_data
                    )
                    db_session.add(new_forecast)

            db_session.commit()
            logger.info(f"üìä Forecast points updated: {updated}")
            logger.info(f"üìä Forecast points created: {created}")
            logger.info(f"\nüéâ Task completed successfully!")
            return True

        except Exception as e:
            db_session.rollback()
            logger.error(f"\n‚ùå {'!'*50}")
            logger.error(f"‚ùå Task FAILED: {str(e)}")
            logger.error(f"‚ùå {'!'*50}")
            traceback.print_exc()
            raise
        finally:
            db_session.close()
    
    async def stop(self):
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö –∑–∞–¥–∞—á"""
        logger.info("üõë Stopping scheduler...")
        self._shutdown_event.set()

        for task in self._running_tasks:
            task.cancel()

        await asyncio.gather(*self._running_tasks, return_exceptions=True)
        self._running_tasks = []
        logger.info("‚úÖ Scheduler stopped")